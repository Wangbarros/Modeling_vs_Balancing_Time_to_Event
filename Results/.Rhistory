print(n)
results <- matrix(NA, nrow = n_rep, ncol = 25)
colnames(results) = c('beta_PS', 'exp_beta_PS', 'ciL_PS','ciU_PS','pval_PS',
'beta_SBW', 'exp_beta_SBW', 'ciL_SBW','ciU_SBW','pval_SBW',
'beta_GLM', 'exp_beta_GLM', 'ciL_GLM','ciU_GLM','pval_GLM',
'beta_cond','target',
'cv_weights_ps', 'cv_weights_sbw', 'cv_weights_glm',
'unweighted_balance',
'ps_balance', 'sbw_balance', 'glm_balance', 'tolerance_sbw')
n_errors = 0
tol_list = c(0.00001, 0.0001, 0.001, 0.01, 0.1)
results_tols = matrix(NA, nrow = n_rep*(length(tol_list)+1), ncol = 11)
colnames(results_tols) = c('beta_cond','target','tol','cv_weights_sbw','sbw_balance',
'beta_SBW', 'exp_beta_SBW', 'ciL_SBW','ciU_SBW','pval_SBW', 'TYPE')
results_prop_hazard = matrix(NA, nrow = n_rep*(length(tol_list)+4), ncol = 5)
colnames(results_prop_hazard) = c('Algorithm','Tolerance','rho','chisq','p_value')
i=1
j = 1
k = 1
while(i <= n_rep){
i_back = i
j_back = j
k_back = k
tryCatch({
if (state == '_misspec_'){
if (scenario == 'A'){
non_linear = 0
non_additive = 0
}
if (scenario == 'B'){
non_linear = 1
non_additive = 0
}
if (scenario == 'C'){
non_linear = 3
non_additive = 0
}
if (scenario == 'D'){
non_linear = 0
non_additive = 4
}
if (scenario == 'E'){
non_linear = 1
non_additive = 4
}
if (scenario == 'F'){
non_linear = 0
non_additive = 10
}
if (scenario == 'G'){
non_linear = 3
non_additive = 10
}
}
print(paste("i =", i))
#targets = c(1, 2, 0.5, 1.25, 0.8, 0.25, 4, 10, 0.1)
targets = c(0.8)
target_beta = sample(x = targets, size = 1)
if (state == '_misspec_'){
sim_res = misspec_surv_data(n = n, lambda = lambda, eta = eta,
scenario = scenario, m = 1, k = 1, target_beta = target_beta,
censoring_p = censoring_p, type_censoring = type_censoring,
hidden = hidden)
} else{
sim_res <- simple_surv_data(n = n, p = p, hidden = hidden,
non_additive = non_additive, non_linear = non_linear,
lambda = lambda, eta = eta, target_beta = target_beta,
censoring_p = censoring_p, type_censoring = type_censoring)
}
sim_res_list[[i]] = sim_res
data = sim_res$data
sum(data$event)
if (over_linear > 0 | over_additive > 0){
# ## continuous times continuous
# data$'X2:X2' = data$X2*data$X2
# data$'X4:X4' = data$X4*data$X4
# data$'X7:X7' = data$X7*data$X7
# data$'X10:X10' = data$X10*data$X10
#
# ## binary times continuous
# data$'X1:X2' = data$X1*data$X2
# data$'X1:X4' = data$X1*data$X4
# data$'X1:X7' = data$X1*data$X7
# data$'X1:X10' = data$X1*data$X10
#
# data$'X3:X2' = data$X3*data$X2
# data$'X3:X4' = data$X3*data$X4
# data$'X3:X7' = data$X3*data$X7
# data$'X3:X10' = data$X3*data$X10
#
# data$'X5:X2' = data$X5*data$X2
# data$'X5:X4' = data$X5*data$X4
# data$'X5:X7' = data$X5*data$X7
# data$'X5:X10' = data$X5*data$X10
#
# data$'X6:X2' = data$X6*data$X2
# data$'X6:X4' = data$X6*data$X4
# data$'X6:X7' = data$X6*data$X7
# data$'X6:X10' = data$X6*data$X10
#
# data$'X8:X2' = data$X8*data$X2
# data$'X8:X4' = data$X8*data$X4
# data$'X8:X7' = data$X8*data$X7
# data$'X8:X10' = data$X8*data$X10
#
# data$'X9:X2' = data$X9*data$X2
# data$'X9:X4' = data$X9*data$X4
# data$'X9:X7' = data$X9*data$X7
# data$'X9:X10' = data$X9*data$X10
#nums <- unlist(lapply(x, is.numeric))
new_matrix = model.matrix( ~(.-1-event-Y-Treatment)^2, data=data)
new_matrix = cbind(data$Y, data$event, data$Treatment, new_matrix)
new_matrix = as.data.frame(new_matrix)
new_matrix$'X2:X2' = new_matrix$X2*new_matrix$X2
new_matrix$'X4:X4' = new_matrix$X4*new_matrix$X4
new_matrix$'X7:X7' = new_matrix$X7*new_matrix$X7
new_matrix$'X10:X10' = new_matrix$X10*new_matrix$X10
colnames(new_matrix)[1] = 'Y'
colnames(new_matrix)[2] = 'event'
colnames(new_matrix)[3] = 'Treatment'
data = new_matrix
}
tapply(data$Y, data$Treatment, summary)
tapply(data$Y, data$event, summary)
sum(data$Treatment)
betaT = sim_res$betaT
results[i, 16] <- betaT
results[i, 17] <- target_beta
t_id <- which(data$Treatment == 1)
c_id <- which(data$Treatment == 0)
data <- data[c(t_id, c_id), ]
if(censoring_weights && censoring_p>0){
glm_censoring = glm(event ~. -Y , data = data, family = 'binomial')
weights_censoring = 1-glm_censoring$fitted.values
weights_censoring = 1/weights_censoring
} else{
weights_censoring = rep(1, times = length(data$Y))
}
#data$set = 1:nrow(data)
#mla <- paste("survival::Surv(time = Y, event = event) ~ . + cluster(set)")
#unweighted_coxph <- survival::coxph(as.formula(fmla), data = data)
#exp(betaT)
#exp(unweighted_coxph$coefficients[1]) get the conditional, mainly for testing
#####################
#IPTW-PS
#####################
###################################################################################################
# Step 1: use lasso propensity score matching to find the matched sample for which
# standardized mean difference for all covariates are as small as possible. Compute the propensity
# score weights from the propensity score resulting in best balance (as defined above).
###################################################################################################
if(do_ps){
glmnet_ps <- ps_est_func(data)
results[i, 18] = sqrt(var(glmnet_ps))/mean(glmnet_ps)
weights <- ifelse(data$Treatment == 1, 1, glmnet_ps/(1-glmnet_ps))
weights = weights*weights_censoring
ps_weighting_data <- cbind(data, weights)
ps_balance = balance(ps_weighting_data)
results[i, 21] = mean(ps_balance$non_weighted)
results[i, 22] = mean(ps_balance$weighted)
###################################################################################################
# Step 2: Estimate the marginal hazard ratio with coxph and robust variance.
###################################################################################################
result_line = weights_cox_reg(weighting_data = ps_weighting_data)
result_line = unlist(result_line)
results[i, 1:5] <- c(result_line[1:5])
results_prop_hazard[k, 1:2] = c('PS','NA')
results_prop_hazard[k, 3:5] = result_line[6:8]
k = k+1
}
#####################
#IPTW-SBW
#####################
###################################################################################################
# Step 1: use sbw to find weighted sample for which
# all the covariates are finely balanced.
###################################################################################################
results_sbw = find_lowest_tol(data)
sbw_weighting_object = results_sbw$sbw_weighting_object
lowest_tolerance = results_sbw$tolerance
col_keep = which(colnames(data)  %in% c('Y', 'event'))
sbw_weighting_data <- cbind(data[, col_keep], sbw_weighting_object$dat_weights)
sbw_weighting_data$weights = sbw_weighting_data$weights*weights_censoring
results[i, 19] = sqrt(var(sbw_weighting_data[sbw_weighting_data$Treatment == 0, "weights"]))/
mean(sbw_weighting_data[sbw_weighting_data$Treatment == 0, "weights"])
sbw_weighting_data[sbw_weighting_data$Treatment == 1, "weights"] <- 1/length(t_id)
sbw_balance = balance(sbw_weighting_data, sbw = TRUE)
results[i, 23] = mean(sbw_balance$weighted)
###################################################################################################
# Step 2: Estimate the marginal hazard ratio with coxph and robust variance.
###################################################################################################
result_line = weights_cox_reg(sbw_weighting_data, double_weights = FALSE)
result_line = unlist(result_line)
results[i, 6:10] <- c(result_line[1:5])
results[i, 25] = lowest_tolerance
results_prop_hazard[k, 1:2] = c('SBW',lowest_tolerance)
results_prop_hazard[k, 3:5] = result_line[6:8]
k = k+1
#####################
#Logistic-PS
#####################
###################################################################################################
# Step 1: Compute the propensity score using logistic regression followed by the weights.
###################################################################################################
if(do_glm){
glm_res = glm(Treatment ~. -Y -event, data = data, family = 'binomial')
results[i, 20] = sqrt(var(glm_res$fitted.values))/mean(glm_res$fitted.values)
weights = ifelse(data$Treatment == 1, 1, glm_res$fitted.values/(1-glm_res$fitted.values))
weights = weights*weights_censoring
glm_weighting_data <- cbind(data, weights)
glm_balance = balance(glm_weighting_data)
results[i, 24] = mean(glm_balance$weighted)
###################################################################################################
# Step 2: Estimate the marginal hazard ratio with coxph and robust variance.
###################################################################################################
result_line = weights_cox_reg(glm_weighting_data)
result_line = unlist(result_line)
results[i, 11:15] <- c(result_line[1:5])
results_prop_hazard[k, 1:2] = c('GLM','NA')
results_prop_hazard[k, 3:5] = result_line[6:8]
k = k+1
}
if(do_tol_loop){
for (tol in tol_list){
# The idea is checking if convergence with tol = 0 works.
# If it doesn't, start a bissection method to find the lowest tol which works.
col_remove <- which(colnames(data)  %in% c('Y', 'event', 'censored', 'Treatment'))
mom_covs <- data[ , -c(col_remove)]
mom_tols <- absstddif(mom_covs, data$Treatment, tol)
col_remove <- which(colnames(data)  %in% c('Y', 'event', 'censored'))
sbw_weighting_object <- sbw::sbw(dat = data[ , -c(col_remove)],
ind = 'Treatment', out = 'treated',
bal = list(bal_cov = names(mom_covs), bal_alg = FALSE,
bal_tol = mom_tols, bal_std = FALSE,
bal_sam = 1000), wei = list(wei_sum = TRUE, wei_pos =TRUE),
sol = list(sol_nam = "gurobi", sol_dis = FALSE),
par = list(par_est = "att", par_tar = NULL))
col_keep = which(colnames(data)  %in% c('Y', 'event'))
sbw_weighting_data <- cbind(data[, col_keep], sbw_weighting_object$dat_weights)
sbw_weighting_data$weights = sbw_weighting_data$weights*weights_censoring
results_tols[j, 1] <- betaT
results_tols[j, 2] <- target_beta
results_tols[j, 3] = tol
results_tols[j, 4] = sqrt(var(sbw_weighting_data[sbw_weighting_data$Treatment == 0, "weights"]))/
mean(sbw_weighting_data[sbw_weighting_data$Treatment == 0, "weights"])
sbw_weighting_data[sbw_weighting_data$Treatment == 1, "weights"] <- 1/length(t_id)
sbw_balance = balance(sbw_weighting_data, sbw = TRUE)
results_tols[j, 5] = mean(sbw_balance$weighted)
###################################################################################################
# Step 2: Estimate the marginal hazard ratio with coxph and robust variance.
###################################################################################################
result_line = weights_cox_reg(sbw_weighting_data)
result_line = unlist(result_line)
results_tols[j, 6:10] <- c(result_line[1:5])
results_tols[j, 11] = 1
j = j+1
results_prop_hazard[k, 1:2] = c('SBW',tol)
results_prop_hazard[k, 3:5] = result_line[6:8]
k = k+1
}
###### WITH ZUBIZARRETA ALG
col_remove <- which(colnames(data)  %in% c('Y', 'event', 'censored', 'Treatment'))
mom_covs <- data[ , -c(col_remove)]
col_remove <- which(colnames(data)  %in% c('Y', 'event', 'censored'))
sbw_weighting_object <- sbw::sbw(dat = data[ , -c(col_remove)],
ind = 'Treatment', out = NULL,
bal = list(bal_cov = names(mom_covs), bal_alg = TRUE,
bal_std = FALSE,
bal_sam = 1000), wei = list(wei_sum = TRUE, wei_pos =TRUE),
sol = list(sol_nam = "gurobi", sol_dis = FALSE),
par = list(par_est = "att", par_tar = NULL))
col_keep = which(colnames(data)  %in% c('Y', 'event'))
sbw_weighting_data <- cbind(data[, col_keep], sbw_weighting_object$dat_weights)
sbw_weighting_data$weights = sbw_weighting_data$weights*weights_censoring
results_tols[j, 1] <- betaT
results_tols[j, 2] <- target_beta
results_tols[j, 3] = sbw_weighting_object$target$bal_tol_ori
results_tols[j, 4] = sqrt(var(sbw_weighting_data[sbw_weighting_data$Treatment == 0, "weights"]))/
mean(sbw_weighting_data[sbw_weighting_data$Treatment == 0, "weights"])
sbw_weighting_data[sbw_weighting_data$Treatment == 1, "weights"] <- 1/length(t_id)
sbw_balance = balance(sbw_weighting_data, sbw = TRUE)
results_tols[j, 5] = mean(sbw_balance$weighted)
###################################################################################################
# Step 2: Estimate the marginal hazard ratio with coxph and robust variance.
###################################################################################################
result_line = weights_cox_reg(sbw_weighting_data)
result_line = unlist(result_line)
results_tols[j, 6:10] <- c(result_line[1:5])
results_tols[j, 11] = 0
j = j+1
results_prop_hazard[k, 1:2] = c('SBW_ZUBI',sbw_weighting_object$target$bal_tol_ori)
results_prop_hazard[k, 3:5] = result_line[6:8]
k = k+1
###### WITH ZUBIZARRETA ALG
}
}, error=function(e){
i <<- i-1
j <<- j_back
k <<- k_back})
i = i+1
}
results = as.data.frame(results)
results_tols = as.data.frame(results_tols)
results_tols$TYPE[results_tols$TYPE == 1] = 'SBW'
results_tols$TYPE[results_tols$TYPE == 0] = 'ZUBI_SBW'
result_table = results_table(results)
results_prop_hazard = as.data.frame(results_prop_hazard)
results_prop_hazard$p_value = as.numeric(as.character((results_prop_hazard$p_value)))
results_prop_hazard$rho = as.numeric(as.character((results_prop_hazard$rho)))
results_prop_hazard$chisq = as.numeric(as.character((results_prop_hazard$chisq)))
results_prop_hazard_glm = results_prop_hazard[results_prop_hazard$Algorithm == 'GLM',]
results_prop_hazard_tol = results_prop_hazard[results_prop_hazard$Algorithm == 'SBW',]
results$relative_ps = abs((results$exp_beta_PS - results$target)/results$target)
results$relative_sbw = abs((results$exp_beta_SBW - results$target)/results$target)
results$relative_glm = abs((results$exp_beta_GLM - results$target)/results$target)
results$relative_diff = (results$relative_glm - results$relative_sbw)/results$relative_glm
results$se_ps = (log(results$ciU_PS) - results$beta_PS)/1.96
results$se_sbw = (log(results$ciU_PS) - results$beta_PS)/1.96
results$se_glm = (log(results$ciU_PS) - results$beta_PS)/1.96
results_tols$relative_sbw = abs((results_tols$exp_beta_SBW - results_tols$target)/results_tols$target)
results_tols$rob_se = (log(results_tols$ciU_SBW) - results_tols$beta_SBW)/1.96
save(results, file = paste0('Results/',state,'sbw_results_n', n, '_nrep', n_rep,
#'_target', target_beta,
# '_tol', tolerance,
'_p', p,
'_hidden', hidden, '_colliders', colliders,
'_nadditive', non_additive, '_nlinear', non_linear,
'_censoring', censoring_p,
'_olinear', over_linear, '_oadditive', over_additive,
'_weightcensoringinv',censoring_weights,
'_.RData'))
save(results_tols, file = paste0('Results/',state,'results_tols_n', n, '_nrep', n_rep,
#'_target', target_beta,
# '_tol', tolerance,
'_p', p,
'_hidden', hidden, '_colliders', colliders,
'_nadditive', non_additive, '_nlinear', non_linear,
'_censoring', censoring_p,
'_olinear', over_linear, '_oadditive', over_additive,
'_weightcensoringinv',censoring_weights,
'_.RData'))
# }
# }
# }
# }
}
results$se_ps = (log(results$ciU_PS) - results$beta_PS)/1.96
results$se_sbw = (log(results$ciU_SBW) - results$beta_SBW)/1.96
results$se_glm = (log(results$ciU_GLM) - results$beta_GLM)/1.96
results_tols$rob_se = (log(results_tols$ciU_SBW) - results_tols$beta_SBW)/1.96
results$coverage_ps = (results$target <= results$ciU_PS & results$target >= results$ciL_PS)
results$coverage_sbw = (results$target <= results$ciU_SBW & results$target >= results$ciL_SBW)
results$coverage_GLM = (results$target <= results$ciU_GLM & results$target >= results$ciL_GLM)
results = results[results$target==0.8,]
results_tols = results_tols[results_tols$target==0.8,]
results_tols_zubi = results_tols[results_tols$TYPE=='ZUBI_SBW',]
results_tols = results_tols[results_tols$TYPE=='SBW',]
round(cbind(results_table_tols(results_tols),tapply(results_tols$relative_sbw, (results_tols$tol), mean)),4)
xtable(round(cbind(results_table_tols(results_tols),tapply(results_tols$relative_sbw, (results_tols$tol), mean)),4),digits = 4)
zubi_average = mean(results_tols_zubi$exp_beta_SBW - results_tols_zubi$target)
zubi_sd = sd(results_tols_zubi$exp_beta_SBW)
zubi_rmse = sqrt((mean(results_tols_zubi$exp_beta_SBW - results_tols_zubi$target) ^ 2) +
var(results_tols_zubi$exp_beta_SBW))
zubi_coverage = mean(results_tols_zubi$target<= results_tols_zubi$ciU_SBW &
results_tols_zubi$target>= results_tols_zubi$ciL_SBW)
zubi_relative= mean(results_tols_zubi$relative_sbw)
xtable(matrix(c(zubi_average,zubi_sd,zubi_rmse,zubi_coverage,zubi_relative),nrow=1),digits=4)
library(xtable)
xtable(round(cbind(results_table_tols(results_tols),tapply(results_tols$relative_sbw, (results_tols$tol), mean)),4),digits = 4)
xtable(matrix(c(zubi_average,zubi_sd,zubi_rmse,zubi_coverage,zubi_relative),nrow=1),digits=4)
round(cbind(results_table(results)[,1:3],rbind(mean(results$coverage_ps),
mean(results$coverage_sbw),
mean(results$coverage_GLM)),
rbind(mean(results$relative_ps),
mean(results$relative_sbw),
mean(results$relative_glm))),4)
mean(results$exp_beta_PS)
mean(results$exp_beta_GLM)
mean(results$exp_beta_SBW)
mean(results_tols_zubi$exp_beta_SBW)
zubi_average
xtable(matrix(c(zubi_average,zubi_sd,zubi_rmse,zubi_coverage,zubi_relative),nrow=1),digits=4)
###
### CENSORING WEIGHTS
###
df_censoring = data.frame(alg = character(), beta = double(), tol = character(), censoring = double())
for (cen_p in seq(0,0.7, 0.1)){
file_1 = paste0('_misspec_results_tols_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUE_.RData')
file_2 = paste0('_misspec_sbw_results_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUE_.RData')
load(file_1)
load(file_2)
df_censoring =  rbind(df_censoring,
data.frame(alg = 'GLM', beta = results$exp_beta_GLM, tol = NA, censoring = cen_p),
data.frame(alg = 'LASSO', beta = results$exp_beta_PS, tol = NA, censoring = cen_p),
data.frame(alg = results_tols$TYPE, beta = results_tols$exp_beta_SBW,
tol = as.numeric(as.character(results_tols$tol)), censoring = cen_p))
}
rm(list=ls())
setwd("~/Dropbox/Doktorand/Dok_Paper_1/Results")
library(ggplot2)
organize_df = function(df_censoring){
df_censoring$alg2 = paste0(df_censoring$alg,'_' ,df_censoring$tol)
df_censoring$alg2[df_censoring$alg == 'ZUBI_SBW'] = 'SBW_ALG'
df_censoring$alg2[df_censoring$alg == 'GLM'] = 'IPTW_GLM'
df_censoring$alg2[df_censoring$alg == 'LASSO'] = 'IPTW_LASSO'
df_censoring = df_censoring[df_censoring$alg2 != "SBW_1e-05",]
df_censoring = df_censoring[df_censoring$alg2 != "SBW_1e-04",]
df_censoring$alg2[df_censoring$alg == 'LASSO'] = 'IPTW_LASSO'
return(df_censoring)
}
###
### CENSORING WEIGHTS
###
df_censoring = data.frame(alg = character(), beta = double(), tol = character(), censoring = double())
for (cen_p in seq(0,0.7, 0.1)){
file_1 = paste0('_misspec_results_tols_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUE_.RData')
file_2 = paste0('_misspec_sbw_results_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUE_.RData')
load(file_1)
load(file_2)
df_censoring =  rbind(df_censoring,
data.frame(alg = 'GLM', beta = results$exp_beta_GLM, tol = NA, censoring = cen_p),
data.frame(alg = 'LASSO', beta = results$exp_beta_PS, tol = NA, censoring = cen_p),
data.frame(alg = results_tols$TYPE, beta = results_tols$exp_beta_SBW,
tol = as.numeric(as.character(results_tols$tol)), censoring = cen_p))
}
df_censoring = organize_df(df_censoring)
# Change box plot colors by groups
p<-ggplot(df_censoring, aes(x=as.factor(censoring), y=beta, fill=alg2)) +
geom_boxplot() + geom_hline(yintercept=0.8, linetype="dashed",
color = "red")
p
###
### CENSORING WEIGHTS
###
df_censoring = data.frame(alg = character(), beta = double(), tol = character(), censoring = double())
for (cen_p in seq(0,0.7, 0.1)){
file_1 = paste0('_misspec_results_tols_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUEinv_.RData')
file_2 = paste0('_misspec_sbw_results_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUEinv_.RData')
load(file_1)
load(file_2)
df_censoring =  rbind(df_censoring,
data.frame(alg = 'GLM', beta = results$exp_beta_GLM, tol = NA, censoring = cen_p),
data.frame(alg = 'LASSO', beta = results$exp_beta_PS, tol = NA, censoring = cen_p),
data.frame(alg = results_tols$TYPE, beta = results_tols$exp_beta_SBW,
tol = as.numeric(as.character(results_tols$tol)), censoring = cen_p))
}
df_censoring = organize_df(df_censoring)
for (cen_p in seq(0.1,0.7, 0.1)){
file_1 = paste0('_misspec_results_tols_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUEinv_.RData')
file_2 = paste0('_misspec_sbw_results_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUEinv_.RData')
load(file_1)
load(file_2)
df_censoring =  rbind(df_censoring,
data.frame(alg = 'GLM', beta = results$exp_beta_GLM, tol = NA, censoring = cen_p),
data.frame(alg = 'LASSO', beta = results$exp_beta_PS, tol = NA, censoring = cen_p),
data.frame(alg = results_tols$TYPE, beta = results_tols$exp_beta_SBW,
tol = as.numeric(as.character(results_tols$tol)), censoring = cen_p))
}
###
### CENSORING WEIGHTS
###
df_censoring = data.frame(alg = character(), beta = double(), tol = character(), censoring = double())
for (cen_p in seq(0,0.7, 0.1)){
file_1 = paste0('_misspec_results_tols_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringinvTRUE_.RData')
file_2 = paste0('_misspec_sbw_results_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringinvTRUE_.RData')
load(file_1)
load(file_2)
df_censoring =  rbind(df_censoring,
data.frame(alg = 'GLM', beta = results$exp_beta_GLM, tol = NA, censoring = cen_p),
data.frame(alg = 'LASSO', beta = results$exp_beta_PS, tol = NA, censoring = cen_p),
data.frame(alg = results_tols$TYPE, beta = results_tols$exp_beta_SBW,
tol = as.numeric(as.character(results_tols$tol)), censoring = cen_p))
}
df_censoring = organize_df(df_censoring)
# Change box plot colors by groups
p<-ggplot(df_censoring, aes(x=as.factor(censoring), y=beta, fill=alg2)) +
geom_boxplot() + geom_hline(yintercept=0.8, linetype="dashed",
color = "red")
p
###
### CENSORING WEIGHTS
###
df_censoring = data.frame(alg = character(), beta = double(), tol = character(), censoring = double())
for (cen_p in seq(0,0.7, 0.1)){
file_1 = paste0('_misspec_results_tols_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUE_.RData')
file_2 = paste0('_misspec_sbw_results_n1500_nrep1000_p10_hidden0_colliders0_nadditive0_nlinear0_censoring'
,cen_p,'_olinear0_oadditive0_weightcensoringTRUE_.RData')
load(file_1)
load(file_2)
df_censoring =  rbind(df_censoring,
data.frame(alg = 'GLM', beta = results$exp_beta_GLM, tol = NA, censoring = cen_p),
data.frame(alg = 'LASSO', beta = results$exp_beta_PS, tol = NA, censoring = cen_p),
data.frame(alg = results_tols$TYPE, beta = results_tols$exp_beta_SBW,
tol = as.numeric(as.character(results_tols$tol)), censoring = cen_p))
}
df_censoring = organize_df(df_censoring)
# Change box plot colors by groups
p<-ggplot(df_censoring, aes(x=as.factor(censoring), y=beta, fill=alg2)) +
geom_boxplot() + geom_hline(yintercept=0.8, linetype="dashed",
color = "red")
p
